{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4369cac8",
   "metadata": {
    "papermill": {
     "duration": 0.003718,
     "end_time": "2025-10-27T06:55:37.903136",
     "exception": false,
     "start_time": "2025-10-27T06:55:37.899418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BLIP Caption Reproduction (COCO)\n",
    "\n",
    "This notebook reproduces the BLIP captioning evaluation on the COCO dataset using the official repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76947b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T06:55:37.910473Z",
     "iopub.status.busy": "2025-10-27T06:55:37.910203Z",
     "iopub.status.idle": "2025-10-27T06:55:39.092717Z",
     "shell.execute_reply": "2025-10-27T06:55:39.091711Z"
    },
    "papermill": {
     "duration": 1.187408,
     "end_time": "2025-10-27T06:55:39.093978",
     "exception": false,
     "start_time": "2025-10-27T06:55:37.906570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/BLIP\n",
      "total 7380\n",
      "drwxr-xr-x 7 root root    4096 Oct 27 06:55 .\n",
      "drwxr-xr-x 3 root root    4096 Oct 27 06:55 ..\n",
      "-rw-r--r-- 1 root root 6707660 Oct 27 06:55 BLIP.gif\n",
      "-rw-r--r-- 1 root root    5159 Oct 27 06:55 CODE_OF_CONDUCT.md\n",
      "-rw-r--r-- 1 root root     140 Oct 27 06:55 CODEOWNERS\n",
      "-rw-r--r-- 1 root root     350 Oct 27 06:55 cog.yaml\n",
      "drwxr-xr-x 2 root root    4096 Oct 27 06:55 configs\n",
      "drwxr-xr-x 2 root root    4096 Oct 27 06:55 data\n",
      "-rw-r--r-- 1 root root  687080 Oct 27 06:55 demo.ipynb\n",
      "-rw-r--r-- 1 root root    4249 Oct 27 06:55 eval_nocaps.py\n",
      "-rw-r--r-- 1 root root    9531 Oct 27 06:55 eval_retrieval_video.py\n",
      "drwxr-xr-x 8 root root    4096 Oct 27 06:55 .git\n",
      "-rw-r--r-- 1 root root    1482 Oct 27 06:55 LICENSE.txt\n",
      "drwxr-xr-x 2 root root    4096 Oct 27 06:55 models\n",
      "-rw-r--r-- 1 root root    3796 Oct 27 06:55 predict.py\n",
      "-rw-r--r-- 1 root root    6666 Oct 27 06:55 pretrain.py\n",
      "-rw-r--r-- 1 root root    9544 Oct 27 06:55 README.md\n",
      "-rw-r--r-- 1 root root      65 Oct 27 06:55 requirements.txt\n",
      "-rw-r--r-- 1 root root     401 Oct 27 06:55 SECURITY.md\n",
      "-rw-r--r-- 1 root root    8388 Oct 27 06:55 train_caption.py\n",
      "-rw-r--r-- 1 root root    8060 Oct 27 06:55 train_nlvr.py\n",
      "-rw-r--r-- 1 root root   14091 Oct 27 06:55 train_retrieval.py\n",
      "-rw-r--r-- 1 root root    7751 Oct 27 06:55 train_vqa.py\n",
      "drwxr-xr-x 2 root root    4096 Oct 27 06:55 transform\n",
      "-rw-r--r-- 1 root root    8474 Oct 27 06:55 utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'BLIP'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /kaggle/working\n",
    "if [ ! -d BLIP ]; then\n",
    "  git clone https://github.com/salesforce/BLIP.git\n",
    "fi\n",
    "cd BLIP\n",
    "pwd\n",
    "ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90640301",
   "metadata": {
    "papermill": {
     "duration": 0.002772,
     "end_time": "2025-10-27T06:55:39.100060",
     "exception": false,
     "start_time": "2025-10-27T06:55:39.097288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e5152e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T06:55:39.108725Z",
     "iopub.status.busy": "2025-10-27T06:55:39.108411Z",
     "iopub.status.idle": "2025-10-27T06:57:28.658928Z",
     "shell.execute_reply": "2025-10-27T06:57:28.658155Z"
    },
    "papermill": {
     "duration": 109.559826,
     "end_time": "2025-10-27T06:57:28.662823",
     "exception": false,
     "start_time": "2025-10-27T06:55:39.102997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 235.4/235.4 kB 10.3 MB/s eta 0:00:00\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 113.6/113.6 kB 8.0 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 377.0/377.0 kB 18.1 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.2/7.2 MB 102.9 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 113.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 29.7 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 4.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 96.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 73.4 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 46.0 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 2.5 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 5.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 30.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 2.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 9.1 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 67.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 109.5/109.5 kB 4.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 104.3/104.3 MB 16.7 MB/s eta 0:00:00\n",
      "CUDA: True\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "ruamel.yaml: 0.17.21\n",
      "PyYAML: 6.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "kaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.30.2 which is incompatible.\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "cd /kaggle/working/BLIP\n",
    "pip install -q timm==0.4.12 fairscale==0.4.4 transformers==4.30.2 tokenizers==0.13.3\n",
    "pip install -q pyyaml ruamel.yaml==0.17.21 tqdm\n",
    "pip install -q pycocoevalcap || pip install -q git+https://github.com/salaniz/pycocoevalcap\n",
    "python - <<'PY'\n",
    "import torch, ruamel.yaml, yaml\n",
    "print('CUDA:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "print('ruamel.yaml:', ruamel.yaml.__version__)\n",
    "print('PyYAML:', yaml.__version__)\n",
    "PY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d005b58",
   "metadata": {
    "papermill": {
     "duration": 0.002912,
     "end_time": "2025-10-27T06:57:28.668912",
     "exception": false,
     "start_time": "2025-10-27T06:57:28.666000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Provide ruamel_yaml shim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d49bc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T06:57:28.676236Z",
     "iopub.status.busy": "2025-10-27T06:57:28.675631Z",
     "iopub.status.idle": "2025-10-27T06:57:28.685878Z",
     "shell.execute_reply": "2025-10-27T06:57:28.685343Z"
    },
    "papermill": {
     "duration": 0.01501,
     "end_time": "2025-10-27T06:57:28.686948",
     "exception": false,
     "start_time": "2025-10-27T06:57:28.671938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working/BLIP\n",
    "cat <<'PY' > ruamel_yaml.py\n",
    "from ruamel import yaml as _yaml\n",
    "\n",
    "__all__ = [name for name in dir(_yaml) if not name.startswith('_')]\n",
    "globals().update({name: getattr(_yaml, name) for name in __all__})\n",
    "PY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a2b7c",
   "metadata": {
    "papermill": {
     "duration": 0.002807,
     "end_time": "2025-10-27T06:57:28.692730",
     "exception": false,
     "start_time": "2025-10-27T06:57:28.689923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download caption checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c64a8e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T06:57:28.699537Z",
     "iopub.status.busy": "2025-10-27T06:57:28.699137Z",
     "iopub.status.idle": "2025-10-27T06:57:50.251000Z",
     "shell.execute_reply": "2025-10-27T06:57:50.250190Z"
    },
    "papermill": {
     "duration": 21.55656,
     "end_time": "2025-10-27T06:57:50.252188",
     "exception": false,
     "start_time": "2025-10-27T06:57:28.695628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 06:57:50 URL:https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_caption_capfilt_large.pth [896081425/896081425] -> \"checkpoints/model_base_caption_capfilt_large.pth\" [1]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "cd /kaggle/working/BLIP\n",
    "mkdir -p checkpoints\n",
    "wget -nv -P checkpoints https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_caption_capfilt_large.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448166d",
   "metadata": {
    "papermill": {
     "duration": 0.003043,
     "end_time": "2025-10-27T06:57:50.258659",
     "exception": false,
     "start_time": "2025-10-27T06:57:50.255616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare COCO image directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1fa2b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T06:57:50.266336Z",
     "iopub.status.busy": "2025-10-27T06:57:50.266086Z",
     "iopub.status.idle": "2025-10-27T06:57:52.309842Z",
     "shell.execute_reply": "2025-10-27T06:57:52.308932Z"
    },
    "papermill": {
     "duration": 2.049326,
     "end_time": "2025-10-27T06:57:52.311049",
     "exception": false,
     "start_time": "2025-10-27T06:57:50.261723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train2014: 82,783 images\n",
      "Sample: ['COCO_train2014_000000263229.jpg', 'COCO_train2014_000000381595.jpg', 'COCO_train2014_000000147733.jpg', 'COCO_train2014_000000559395.jpg', 'COCO_train2014_000000374072.jpg']\n",
      "val2014: 40,504 images\n",
      "Sample: ['COCO_val2014_000000540531.jpg', 'COCO_val2014_000000159103.jpg', 'COCO_val2014_000000155671.jpg', 'COCO_val2014_000000033441.jpg', 'COCO_val2014_000000014321.jpg']\n",
      "Total images inspected: 123,287\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_dir = Path('/kaggle/input/coco2014/train2014/train2014')\n",
    "val_dir = Path('/kaggle/input/coco2014/val2014/val2014')\n",
    "\n",
    "def count_images(directory: Path):\n",
    "    if not directory.exists():\n",
    "        print(f'{directory} does not exist')\n",
    "        return 0\n",
    "    files = list(directory.glob('*.jpg'))\n",
    "    print(f'{directory.name}: {len(files):,} images')\n",
    "    print('Sample:', [p.name for p in files[:5]])\n",
    "    return len(files)\n",
    "\n",
    "train_total = count_images(train_dir)\n",
    "val_total = count_images(val_dir)\n",
    "print(f'Total images inspected: {train_total + val_total:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f8364e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T06:57:52.319436Z",
     "iopub.status.busy": "2025-10-27T06:57:52.319012Z",
     "iopub.status.idle": "2025-10-27T07:00:15.141134Z",
     "shell.execute_reply": "2025-10-27T07:00:15.140416Z"
    },
    "papermill": {
     "duration": 142.830384,
     "end_time": "2025-10-27T07:00:15.145475",
     "exception": false,
     "start_time": "2025-10-27T06:57:52.315091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked 82783 train images.\n",
      "Linked 10000 val/test images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "src_train = Path(\"/kaggle/input/coco2014/train2014/train2014\")\n",
    "src_val = Path(\"/kaggle/input/coco2014/val2014/val2014\")\n",
    "dest_root = Path(\"/kaggle/working/coco_images\")\n",
    "dest_train = dest_root / \"train2014\"\n",
    "dest_val = dest_root / \"val2014\"\n",
    "\n",
    "# ensure annotation files available locally\n",
    "ann_root = Path(\"/kaggle/working/annotation\")\n",
    "ann_root.mkdir(parents=True, exist_ok=True)\n",
    "urls = {\n",
    "    \"val\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\",\n",
    "    \"test\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\",\n",
    "}\n",
    "for split, url in urls.items():\n",
    "    target = ann_root / f\"coco_karpathy_{split}.json\"\n",
    "    if not target.exists():\n",
    "        urlretrieve(url, target)\n",
    "\n",
    "# rebuild destination tree cleanly\n",
    "if dest_root.exists():\n",
    "    shutil.rmtree(dest_root)\n",
    "dest_train.mkdir(parents=True, exist_ok=True)\n",
    "dest_val.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def safe_symlink(src: Path, dst: Path):\n",
    "    if not src.exists():\n",
    "        return False\n",
    "    if dst.exists():\n",
    "        return True\n",
    "    dst.symlink_to(src.resolve())\n",
    "    return True\n",
    "\n",
    "# expose train images (already named COCO_train2014_XXXXXX.jpg)\n",
    "train_count = 0\n",
    "for path in src_train.glob(\"*.jpg\"):\n",
    "    if safe_symlink(path, dest_train / path.name):\n",
    "        train_count += 1\n",
    "\n",
    "# collect images required for val/test splits\n",
    "required = set()\n",
    "for split in (\"val\", \"test\"):\n",
    "    ann_path = ann_root / f\"coco_karpathy_{split}.json\"\n",
    "    with ann_path.open('r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data:\n",
    "        required.add(item[\"image\"].split('/')[1])  # e.g. COCO_val2014_000000184613.jpg\n",
    "\n",
    "missing = []\n",
    "linked = 0\n",
    "for filename in sorted(required):\n",
    "    candidates = [\n",
    "        src_train / filename.replace(\"val2014\", \"train2014\"),\n",
    "        src_val / filename,\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if safe_symlink(candidate, dest_val / filename):\n",
    "            linked += 1\n",
    "            break\n",
    "    else:\n",
    "        missing.append(filename)\n",
    "\n",
    "print(f\"Linked {train_count} train images.\")\n",
    "print(f\"Linked {linked} val/test images.\")\n",
    "if missing:\n",
    "    print(\"Missing files:\", missing[:10])\n",
    "    raise FileNotFoundError(f\"{len(missing)} images could not be located in the provided datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbaf72ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T07:00:15.152935Z",
     "iopub.status.busy": "2025-10-27T07:00:15.152338Z",
     "iopub.status.idle": "2025-10-27T07:00:16.078421Z",
     "shell.execute_reply": "2025-10-27T07:00:16.077344Z"
    },
    "papermill": {
     "duration": 0.931264,
     "end_time": "2025-10-27T07:00:16.079976",
     "exception": false,
     "start_time": "2025-10-27T07:00:15.148712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/annotation/coco_gt\n",
    "!cp /kaggle/input/coco2014/captions/annotations/captions_val2014.json /kaggle/working/annotation/coco_gt/\n",
    "!cp /kaggle/input/coco2014/captions/annotations/captions_train2014.json /kaggle/working/annotation/coco_gt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaffd80",
   "metadata": {
    "papermill": {
     "duration": 0.003311,
     "end_time": "2025-10-27T07:00:16.086889",
     "exception": false,
     "start_time": "2025-10-27T07:00:16.083578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Update caption evaluation config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5be8feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T07:00:16.094515Z",
     "iopub.status.busy": "2025-10-27T07:00:16.094239Z",
     "iopub.status.idle": "2025-10-27T07:00:16.125473Z",
     "shell.execute_reply": "2025-10-27T07:00:16.124764Z"
    },
    "papermill": {
     "duration": 0.036238,
     "end_time": "2025-10-27T07:00:16.126490",
     "exception": false,
     "start_time": "2025-10-27T07:00:16.090252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated config entries:\n",
      "image_root: /kaggle/working/coco_images\n",
      "ann_root: /kaggle/working/annotation\n",
      "coco_gt_root: /kaggle/working/annotation/coco_gt\n",
      "pretrained: checkpoints/model_base_caption_capfilt_large.pth\n"
     ]
    }
   ],
   "source": [
    "from ruamel.yaml import YAML\n",
    "from pathlib import Path\n",
    "\n",
    "yaml = YAML()\n",
    "cfg_path = Path('/kaggle/working/BLIP/configs/caption_coco.yaml')\n",
    "data = yaml.load(cfg_path.read_text())\n",
    "\n",
    "data['image_root'] = '/kaggle/working/coco_images'\n",
    "data['ann_root'] = '/kaggle/working/annotation'\n",
    "data['coco_gt_root'] = '/kaggle/working/annotation/coco_gt'\n",
    "data['pretrained'] = 'checkpoints/model_base_caption_capfilt_large.pth'\n",
    "\n",
    "with cfg_path.open('w', encoding='utf-8') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "print('Updated config entries:')\n",
    "for key in ('image_root', 'ann_root', 'coco_gt_root', 'pretrained'):\n",
    "    print('{}: {}'.format(key, data[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a880e",
   "metadata": {
    "papermill": {
     "duration": 0.003103,
     "end_time": "2025-10-27T07:00:16.132946",
     "exception": false,
     "start_time": "2025-10-27T07:00:16.129843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run COCO caption evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9543a823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T07:00:16.140428Z",
     "iopub.status.busy": "2025-10-27T07:00:16.139935Z",
     "iopub.status.idle": "2025-10-27T07:00:16.147730Z",
     "shell.execute_reply": "2025-10-27T07:00:16.147025Z"
    },
    "papermill": {
     "duration": 0.012753,
     "end_time": "2025-10-27T07:00:16.148878",
     "exception": false,
     "start_time": "2025-10-27T07:00:16.136125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3976"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "utils_path = Path(\"/kaggle/working/BLIP/data/utils.py\")\n",
    "utils_src = utils_path.read_text()\n",
    "\n",
    "patch = \"\"\"def coco_caption_eval(coco_gt_root, results_file, split):\n",
    "    urls = {'val':'https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val_gt.json',\n",
    "            'test':'https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test_gt.json'}\n",
    "    filenames = {'val':'coco_karpathy_val_gt.json','test':'coco_karpathy_test_gt.json'}\n",
    "\n",
    "    download_url(urls[split],coco_gt_root)\n",
    "    annotation_file = os.path.join(coco_gt_root,filenames[split])\n",
    "\n",
    "    # Some hosted Karpathy JSON files are missing the optional COCO 'info' section.\n",
    "    # Newer pycocotools assumes the key exists, so patch up the annotation in-place.\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        annotation_data = json.load(f)\n",
    "    if 'info' not in annotation_data:\n",
    "        annotation_data['info'] = {\"description\": \"Inserted to satisfy pycocotools\"}\n",
    "        with open(annotation_file, 'w') as f:\n",
    "            json.dump(annotation_data, f)\n",
    "\n",
    "    # create coco object and coco_result object\n",
    "    coco = COCO(annotation_file)\n",
    "\"\"\"\n",
    "\n",
    "start = utils_src.index(\"def coco_caption_eval\")\n",
    "end = utils_src.index(\"# create coco object\", start)\n",
    "utils_src = utils_src[:start] + patch + utils_src[end:]\n",
    "\n",
    "utils_path.write_text(utils_src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e18c0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T07:00:16.156587Z",
     "iopub.status.busy": "2025-10-27T07:00:16.156189Z",
     "iopub.status.idle": "2025-10-27T07:00:16.161019Z",
     "shell.execute_reply": "2025-10-27T07:00:16.160298Z"
    },
    "papermill": {
     "duration": 0.009836,
     "end_time": "2025-10-27T07:00:16.162140",
     "exception": false,
     "start_time": "2025-10-27T07:00:16.152304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched data/utils.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"/kaggle/working/BLIP/data/utils.py\")\n",
    "text = path.read_text()\n",
    "text = text.replace(\"    dist.barrier()\\n\",\n",
    "                    \"    if utils.is_dist_avail_and_initialized():\\n        dist.barrier()\\n\")\n",
    "path.write_text(text)\n",
    "print(\"Patched data/utils.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3aee2a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T07:00:16.170216Z",
     "iopub.status.busy": "2025-10-27T07:00:16.169716Z",
     "iopub.status.idle": "2025-10-27T07:00:16.174320Z",
     "shell.execute_reply": "2025-10-27T07:00:16.173695Z"
    },
    "papermill": {
     "duration": 0.009729,
     "end_time": "2025-10-27T07:00:16.175396",
     "exception": false,
     "start_time": "2025-10-27T07:00:16.165667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched blip.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "blip_path = Path(\"/kaggle/working/BLIP/models/blip.py\")\n",
    "text = blip_path.read_text()\n",
    "needle = \"        if not sample:\\n            image_embeds = image_embeds.repeat_interleave(num_beams,dim=0)\\n            \\n\"\n",
    "if needle in text:\n",
    "    text = text.replace(needle, \"\")\n",
    "    blip_path.write_text(text)\n",
    "    print(\"Patched blip.py\")\n",
    "else:\n",
    "    print(\"Patch already applied\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49ff8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T07:00:16.183002Z",
     "iopub.status.busy": "2025-10-27T07:00:16.182777Z",
     "iopub.status.idle": "2025-10-27T07:49:57.066719Z",
     "shell.execute_reply": "2025-10-27T07:49:57.065914Z"
    },
    "papermill": {
     "duration": 2981.041859,
     "end_time": "2025-10-27T07:49:57.220765",
     "exception": false,
     "start_time": "2025-10-27T07:00:16.178906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Creating captioning dataset\n",
      "100%|██████████| 84.6M/84.6M [00:02<00:00, 32.6MB/s]\n",
      "Creating model\n",
      "load checkpoint from checkpoints/model_base_caption_capfilt_large.pth\n",
      "Start training\n",
      "2025-10-27 07:00:49.482697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761548449.725855     113 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761548449.797511     113 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Caption generation:  [  0/157]  eta: 1:00:32    time: 23.1342  data: 1.1662  max mem: 2330\n",
      "Caption generation:  [ 10/157]  eta: 0:18:11    time: 7.4259  data: 0.1063  max mem: 2330\n",
      "Caption generation:  [ 20/157]  eta: 0:15:18    time: 5.8848  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 30/157]  eta: 0:13:39    time: 5.9140  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [ 40/157]  eta: 0:12:19    time: 5.9119  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [ 50/157]  eta: 0:11:07    time: 5.9103  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [ 60/157]  eta: 0:09:59    time: 5.9120  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [ 70/157]  eta: 0:08:54    time: 5.9120  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [ 80/157]  eta: 0:07:51    time: 5.9122  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [ 90/157]  eta: 0:06:48    time: 5.9152  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [100/157]  eta: 0:05:46    time: 5.9131  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [110/157]  eta: 0:04:44    time: 5.9115  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [120/157]  eta: 0:03:43    time: 5.9119  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [130/157]  eta: 0:02:43    time: 5.9114  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [140/157]  eta: 0:01:42    time: 5.9153  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [150/157]  eta: 0:00:42    time: 5.9156  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [156/157]  eta: 0:00:05    time: 5.7070  data: 0.0002  max mem: 2330\n",
      "Caption generation: Total time: 0:15:40 (5.9930 s / it)\n",
      "result file saved to output/caption_coco/result/val_epoch0.json\n",
      "Caption generation:  [  0/157]  eta: 0:18:10    time: 6.9429  data: 0.9930  max mem: 2330\n",
      "Caption generation:  [ 10/157]  eta: 0:14:43    time: 6.0098  data: 0.0905  max mem: 2330\n",
      "Caption generation:  [ 20/157]  eta: 0:13:37    time: 5.9187  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 30/157]  eta: 0:12:35    time: 5.9204  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 40/157]  eta: 0:11:35    time: 5.9201  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 50/157]  eta: 0:10:35    time: 5.9198  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 60/157]  eta: 0:09:35    time: 5.9190  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 70/157]  eta: 0:08:36    time: 5.9190  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 80/157]  eta: 0:07:36    time: 5.9184  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [ 90/157]  eta: 0:06:37    time: 5.9172  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [100/157]  eta: 0:05:37    time: 5.9182  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [110/157]  eta: 0:04:38    time: 5.9184  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [120/157]  eta: 0:03:39    time: 5.9170  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [130/157]  eta: 0:02:40    time: 5.9175  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [140/157]  eta: 0:01:40    time: 5.9196  data: 0.0003  max mem: 2330\n",
      "Caption generation:  [150/157]  eta: 0:00:41    time: 5.9190  data: 0.0002  max mem: 2330\n",
      "Caption generation:  [156/157]  eta: 0:00:05    time: 5.7002  data: 0.0002  max mem: 2330\n",
      "Caption generation: Total time: 0:15:25 (5.8980 s / it)\n",
      "result file saved to output/caption_coco/result/test_epoch0.json\n",
      "100%|██████████| 2.66M/2.66M [00:00<00:00, 4.07MB/s]\n",
      "PTBTokenizer tokenized 307821 tokens at 588380.93 tokens per second.\n",
      "PTBTokenizer tokenized 55788 tokens at 290491.02 tokens per second.\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "Progress: 383.6M / 384.5M ( 99.8%)WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [02:55.531 minutes]\n",
      "Threads( StanfordCoreNLP ) [02:38.216 minutes]\n",
      "Threads( StanfordCoreNLP ) [01:18.441 minutes]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [01:02.487 minutes]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 8.245 min\n",
      "Progress: 384.5M / 384.5M (100.0%)\r\n",
      "Extracting stanford-corenlp-3.6.0 ...\n",
      "Done.\n",
      "computing Bleu score...\n",
      "{'testlen': 50641, 'reflen': 49586, 'guess': [50641, 45641, 40641, 35641], 'correct': [39864, 23611, 12955, 6997]}\n",
      "ratio: 1.0212761666599237\n",
      "Bleu_1: 0.787\n",
      "Bleu_2: 0.638\n",
      "Bleu_3: 0.506\n",
      "Bleu_4: 0.400\n",
      "computing METEOR score...\n",
      "METEOR: 0.309\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.599\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.238\n",
      "Bleu_1: 0.787\n",
      "Bleu_2: 0.638\n",
      "Bleu_3: 0.506\n",
      "Bleu_4: 0.400\n",
      "METEOR: 0.309\n",
      "ROUGE_L: 0.599\n",
      "CIDEr: 1.323\n",
      "SPICE: 0.238\n",
      "100%|██████████| 2.66M/2.66M [00:00<00:00, 4.08MB/s]\n",
      "PTBTokenizer tokenized 307085 tokens at 703857.53 tokens per second.\n",
      "PTBTokenizer tokenized 55487 tokens at 263632.52 tokens per second.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [02:51.869 minutes]\n",
      "Threads( StanfordCoreNLP ) [02:40.587 minutes]\n",
      "Threads( StanfordCoreNLP ) [01:12.849 minutes]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [50.130 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 7.918 min\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 50318, 'reflen': 49273, 'guess': [50318, 45318, 40318, 35318], 'correct': [39689, 23338, 12754, 6800]}\n",
      "ratio: 1.02120836969535\n",
      "Bleu_1: 0.789\n",
      "Bleu_2: 0.637\n",
      "Bleu_3: 0.505\n",
      "Bleu_4: 0.397\n",
      "computing METEOR score...\n",
      "METEOR: 0.310\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.600\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.333\n",
      "computing SPICE score...\n",
      "SPICE: 0.238\n",
      "Bleu_1: 0.789\n",
      "Bleu_2: 0.637\n",
      "Bleu_3: 0.505\n",
      "Bleu_4: 0.397\n",
      "METEOR: 0.310\n",
      "ROUGE_L: 0.600\n",
      "CIDEr: 1.333\n",
      "SPICE: 0.238\n",
      "Training time 0:49:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd /kaggle/working/BLIP\n",
      "+ mkdir -p /kaggle/working/annotation\n",
      "+ mkdir -p output/caption_coco\n",
      "+ unset RANK WORLD_SIZE LOCAL_RANK MASTER_ADDR MASTER_PORT\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python train_caption.py --config ./configs/caption_coco.yaml --output_dir output/caption_coco --evaluate\n",
      "+ tee output/caption_coco/stdout_stderr.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euxo pipefail\n",
    "cd /kaggle/working/BLIP\n",
    "mkdir -p /kaggle/working/annotation\n",
    "mkdir -p output/caption_coco\n",
    "unset RANK WORLD_SIZE LOCAL_RANK MASTER_ADDR MASTER_PORT\n",
    "CUDA_VISIBLE_DEVICES=0 python train_caption.py --config ./configs/caption_coco.yaml --output_dir output/caption_coco --evaluate 2>&1 | tee output/caption_coco/stdout_stderr.log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973b013",
   "metadata": {
    "papermill": {
     "duration": 0.046321,
     "end_time": "2025-10-27T07:49:57.315587",
     "exception": false,
     "start_time": "2025-10-27T07:49:57.269266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract key metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f4c1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T07:49:57.409553Z",
     "iopub.status.busy": "2025-10-27T07:49:57.409262Z",
     "iopub.status.idle": "2025-10-27T07:49:57.465951Z",
     "shell.execute_reply": "2025-10-27T07:49:57.465056Z"
    },
    "papermill": {
     "duration": 0.104305,
     "end_time": "2025-10-27T07:49:57.467207",
     "exception": false,
     "start_time": "2025-10-27T07:49:57.362902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured metrics:\n",
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "SPICE evaluation took: 8.245 min\n",
      "Bleu_1: 0.787\n",
      "Bleu_2: 0.638\n",
      "Bleu_3: 0.506\n",
      "Bleu_4: 0.400\n",
      "computing METEOR score...\n",
      "METEOR: 0.309\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.238\n",
      "Bleu_1: 0.787\n",
      "Bleu_2: 0.638\n",
      "Bleu_3: 0.506\n",
      "Bleu_4: 0.400\n",
      "METEOR: 0.309\n",
      "CIDEr: 1.323\n",
      "SPICE: 0.238\n",
      "SPICE evaluation took: 7.918 min\n",
      "Bleu_1: 0.789\n",
      "Bleu_2: 0.637\n",
      "Bleu_3: 0.505\n",
      "Bleu_4: 0.397\n",
      "computing METEOR score...\n",
      "METEOR: 0.310\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.333\n",
      "computing SPICE score...\n",
      "SPICE: 0.238\n",
      "Bleu_1: 0.789\n",
      "Bleu_2: 0.637\n",
      "Bleu_3: 0.505\n",
      "Bleu_4: 0.397\n",
      "METEOR: 0.310\n",
      "CIDEr: 1.333\n",
      "SPICE: 0.238\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "log = Path('/kaggle/working/BLIP/output/caption_coco/stdout_stderr.log')\n",
    "if not log.exists():\n",
    "    raise FileNotFoundError('No evaluation log found at ' + str(log))\n",
    "lines = log.read_text(errors='ignore').splitlines()\n",
    "print('Captured metrics:')\n",
    "for line in lines:\n",
    "    if any(metric in line for metric in ('CIDEr', 'Bleu_4', 'Bleu_3', 'Bleu_2', 'Bleu_1', 'METEOR', 'SPICE')):\n",
    "        print(line)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 92290,
     "sourceId": 214432,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3263.961376,
   "end_time": "2025-10-27T07:49:57.950020",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-27T06:55:33.988644",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
