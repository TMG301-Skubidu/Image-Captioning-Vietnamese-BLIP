{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLIP NoCaps Evaluation (Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Enable Internet in the Kaggle notebook, and add the dataset containing `nocap_val_4500_captions.json` and `nocaps_test_image_info.json` to the *Data* tab.\n",
    "- The notebook uses run_nocaps_eval.py to download images in parallel; the `--workers` option is set automatically based on `cpu_count()` (typically ~4 cores → 8 workers is safe).\n",
    "- If you already have the images, set `SKIP_DOWNLOAD = True` in the setup cell to skip the download step; the following steps remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "BASE_DIR = Path(\"/kaggle/working\")\n",
    "\n",
    "DATASET_ROOT = Path(\"/kaggle/input/nocaps\")\n",
    "VAL_JSON = DATASET_ROOT / \"nocaps_val_4500_captions.json\"\n",
    "TEST_JSON = DATASET_ROOT / \"nocaps_test_image_info.json\"\n",
    "\n",
    "REPO_URL = \"https://github.com/TMG301-Skubidu/Image-Captioning-Vietnamese-BLIP.git\"\n",
    "REPO_DIR = BASE_DIR / \"BLIP\"\n",
    "CLI_SCRIPT = REPO_DIR / \"tools/run_nocaps_eval.py\"\n",
    "\n",
    "IMAGE_ROOT = BASE_DIR / \"nocaps_images\"\n",
    "ANN_ROOT = BASE_DIR / \"nocaps_annotations\"\n",
    "OUTPUT_DIR = BASE_DIR / \"NoCaps\"\n",
    "\n",
    "SKIP_DOWNLOAD = False  # đặt True nếu đã có đủ ảnh trong IMAGE_ROOT\n",
    "WORKERS_OVERRIDE = None  # đặt số nguyên để ép số worker, None = tự động\n",
    "\n",
    "for path in [IMAGE_ROOT / \"val\", IMAGE_ROOT / \"test\", ANN_ROOT, OUTPUT_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"VAL_JSON exists: {VAL_JSON.exists()} -> {VAL_JSON}\")\n",
    "print(f\"TEST_JSON exists: {TEST_JSON.exists()} -> {TEST_JSON}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "else:\n",
    "    print(f\"Repository already available at {REPO_DIR}\")\n",
    "\n",
    "commit = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=REPO_DIR).decode().strip()\n",
    "print(\"Repository commit:\", commit)\n",
    "for rel_path in [\"eval_nocaps.py\", \"data/nocaps_dataset.py\", \"configs/nocaps.yaml\"]:\n",
    "    path = REPO_DIR / rel_path\n",
    "    status = \"OK\" if path.exists() else \"MISSING\"\n",
    "    print(f\"{rel_path}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "requirements_path = REPO_DIR / \"requirements.txt\"\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(requirements_path)], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(\"Working directory:\", Path.cwd())\n",
    "print(\"Torch:\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Timm:\", timm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_image(entry):\n",
    "    keys = [\"file_name\", \"id\", \"domain\", \"coco_url\", \"open_images_id\"]\n",
    "    return {k: entry.get(k) for k in keys if k in entry}\n",
    "\n",
    "with open(VAL_JSON, \"r\") as f:\n",
    "    val_raw = json.load(f)\n",
    "with open(TEST_JSON, \"r\") as f:\n",
    "    test_raw = json.load(f)\n",
    "\n",
    "val_caps = val_raw.get(\"annotations\", [])\n",
    "print(\"Val keys:\", list(val_raw.keys()))\n",
    "print(\"Val images:\", len(val_raw[\"images\"]))\n",
    "print(\"Val annotations:\", len(val_caps))\n",
    "print(\"Val sample image:\", summarize_image(val_raw[\"images\"][0]))\n",
    "print(\"Val sample captions:\", [ann[\"caption\"] for ann in val_caps[:3]])\n",
    "\n",
    "print(\"Test keys:\", list(test_raw.keys()))\n",
    "print(\"Test images:\", len(test_raw[\"images\"]))\n",
    "print(\"Test has annotations:\", \"annotations\" in test_raw)\n",
    "print(\"Test sample image:\", summarize_image(test_raw[\"images\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "workers_detected = multiprocessing.cpu_count() or 1\n",
    "workers = WORKERS_OVERRIDE or min(32, max(4, workers_detected))\n",
    "print(f\"Detected CPU cores: {workers_detected} -> using {workers} workers\")\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    str(CLI_SCRIPT),\n",
    "    \"--dataset-root\", str(DATASET_ROOT),\n",
    "    \"--image-root\", str(IMAGE_ROOT),\n",
    "    \"--ann-root\", str(ANN_ROOT),\n",
    "    \"--output-dir\", str(OUTPUT_DIR),\n",
    "    \"--batch-size\", \"4\",\n",
    "    \"--workers\", str(workers),\n",
    "    \"--skip-eval\",\n",
    "]\n",
    "if SKIP_DOWNLOAD:\n",
    "    cmd.append(\"--no-download\")\n",
    "\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "subprocess.run(cmd, check=True)\n",
    "\n",
    "failures_log = OUTPUT_DIR / \"download_failures.json\"\n",
    "if failures_log.exists():\n",
    "    failures = json.loads(failures_log.read_text())\n",
    "    print(\"Download failures - val:\", len(failures.get(\"val\", [])), \"| test:\", len(failures.get(\"test\", [])))\n",
    "else:\n",
    "    print(\"No download_failures.json found yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "val_out = ANN_ROOT / \"nocaps_val.json\"\n",
    "test_out = ANN_ROOT / \"nocaps_test.json\"\n",
    "failures_log = OUTPUT_DIR / \"download_failures.json\"\n",
    "\n",
    "if val_out.exists():\n",
    "    val_entries = json.loads(val_out.read_text())\n",
    "    print(\"Val entries:\", len(val_entries), \"->\", val_out)\n",
    "    if val_entries:\n",
    "        print(\"Sample val entry:\", val_entries[0])\n",
    "else:\n",
    "    print(\"Val annotations not ready yet (rerun the data download cell).\")\n",
    "\n",
    "if test_out.exists():\n",
    "    test_entries = json.loads(test_out.read_text())\n",
    "    print(\"Test entries:\", len(test_entries), \"->\", test_out)\n",
    "    if test_entries:\n",
    "        print(\"Sample test entry:\", test_entries[0])\n",
    "else:\n",
    "    print(\"Test annotations not ready yet (rerun the data download cell).\")\n",
    "\n",
    "if failures_log.exists():\n",
    "    failures = json.loads(failures_log.read_text())\n",
    "    print(\"Download failure samples (val):\", failures.get(\"val\", [])[:3])\n",
    "    print(\"Download failure samples (test):\", failures.get(\"test\", [])[:3])\n",
    "else:\n",
    "    print(\"No download_failures.json found (no errors or download not finished yet).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import ruamel_yaml as yaml\n",
    "except ModuleNotFoundError:\n",
    "    from ruamel import yaml  # type: ignore\n",
    "\n",
    "expected_config = OUTPUT_DIR / \"nocaps_eval.yaml\"\n",
    "if expected_config.exists():\n",
    "    config_path = expected_config\n",
    "    config = yaml.load(expected_config.read_text(), Loader=yaml.Loader)\n",
    "else:\n",
    "    print(\"WARNING: not found\", expected_config, \"-> falling back to template.\")\n",
    "    config_path = Path(\"configs/nocaps.yaml\")\n",
    "    config = yaml.load(config_path.read_text(), Loader=yaml.Loader)\n",
    "    config[\"image_root\"] = str(IMAGE_ROOT).replace(\"\\\\\", \"/\")\n",
    "    config[\"ann_root\"] = str(ANN_ROOT).replace(\"\\\\\", \"/\")\n",
    "    config[\"batch_size\"] = min(4, config.get(\"batch_size\", 32))\n",
    "    expected_config = OUTPUT_DIR / \"nocaps_eval.yaml\"\n",
    "    expected_config.write_text(yaml.dump(config))\n",
    "    print(\"Wrote new config to:\", expected_config)\n",
    "\n",
    "print(\"Config path:\", expected_config)\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval_nocaps.py --config /kaggle/working/nocaps_eval.yaml --output_dir /kaggle/working/NoCaps --device cuda --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = OUTPUT_DIR / \"result\"\n",
    "val_result_path = result_dir / \"val.json\"\n",
    "test_result_path = result_dir / \"test.json\"\n",
    "\n",
    "with open(val_result_path, \"r\") as f:\n",
    "    val_result = json.load(f)\n",
    "with open(test_result_path, \"r\") as f:\n",
    "    test_result = json.load(f)\n",
    "\n",
    "print(\"Val captions:\", len(val_result))\n",
    "print(\"Test captions:\", len(test_result))\n",
    "print(\"Sample val captions:\")\n",
    "for sample in val_result[:5]:\n",
    "    print(sample)\n",
    "\n",
    "print(\"Artifacts saved under:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- If `download_failures.json` is not empty, consider manually downloading those images and rerunning the conversion cell.\n",
    "- Compress `nocaps_images`, `nocaps_annotations`, and `NoCaps/result/test.json` into a separate Kaggle dataset so future notebook runs are faster.\n",
    "- Upload `NoCaps/result/test.json` to the NoCaps server to receive the official score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
