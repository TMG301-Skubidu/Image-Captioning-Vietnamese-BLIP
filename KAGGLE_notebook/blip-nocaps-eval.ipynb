{
          "cells": [
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "# BLIP NoCaps Evaluation (Kaggle)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "- Enable Internet in the Kaggle notebook, and add the dataset containing `nocap_val_4500_captions.json` and `nocaps_test_image_info.json` to the *Data* tab.\n",
                                        "- The notebook uses run_nocaps_eval.py to download images in parallel; the `--workers` option is set automatically based on `cpu_count()` (typically ~4 cores → 8 workers is safe).\n",
                                        "- If you already have the images, set `SKIP_DOWNLOAD = True` in the setup cell to skip the download step; the following steps remain unchanged."
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "from pathlib import Path\n",
                                        "import json\n",
                                        "import os\n",
                                        "\n",
                                        "BASE_DIR = Path(\"/kaggle/working\")\n",
                                        "\n",
                                        "# NOCAPS JSON (add dataset via Data tab)\n",
                                        "DATASET_ROOT = Path(\"/kaggle/input/nocaps\")\n",
                                        "VAL_JSON = DATASET_ROOT / \"nocaps_val_4500_captions.json\"\n",
                                        "TEST_JSON = DATASET_ROOT / \"nocaps_test_image_info.json\"\n",
                                        "\n",
                                        "# COCO 2014 (re-use local images on Kaggle)\n",
                                        "COCO_IMG_TRAIN = Path(\"/kaggle/input/coco2014/train2014/train2014\")\n",
                                        "COCO_IMG_VAL = Path(\"/kaggle/input/coco2014/val2014/val2014\")\n",
                                        "\n",
                                        "# Try to detect an Open Images dataset attached via Data tab\n",
                                        "CANDIDATE_OPENIM_ROOTS = [\n",
                                        "    Path(\"/kaggle/input/openimages\"),\n",
                                        "    Path(\"/kaggle/input/open-images-v6\"),\n",
                                        "    Path(\"/kaggle/input/open-images\"),\n",
                                        "    Path(\"/kaggle/input/openimagesv6\"),\n",
                                        "]\n",
                                        "OPENIM_ROOT = next((p for p in CANDIDATE_OPENIM_ROOTS if p.exists()), None)\n",
                                        "\n",
                                        "# Repo/script location: prefer local tools/, fallback to clone\n",
                                        "REPO_URL = \"https://github.com/TMG301-Skubidu/Image-Captioning-Vietnamese-BLIP.git\"\n",
                                        "REPO_DIR = BASE_DIR / \"BLIP\"\n",
                                        "PREFER_LOCAL_CLI = Path(\"tools/run_nocaps_eval.py\")\n",
                                        "CLI_SCRIPT = PREFER_LOCAL_CLI if PREFER_LOCAL_CLI.exists() else (REPO_DIR / \"tools/run_nocaps_eval.py\")\n",
                                        "\n",
                                        "IMAGE_ROOT = BASE_DIR / \"nocaps_images\"\n",
                                        "ANN_ROOT = BASE_DIR / \"nocaps_annotations\"\n",
                                        "OUTPUT_DIR = BASE_DIR / \"NoCaps\"\n",
                                        "\n",
                                        "# Controls\n",
                                        "SKIP_DOWNLOAD = False  # True nếu đã có đủ ảnh hoặc chạy offline\n",
                                        "EVAL_WITH_SCRIPT = False  # True: chạy eval ngay trong CLI_SCRIPT (không cần eval_nocaps.py riêng)\n",
                                        "USE_OPENIM_CLI = True  # True để tải Open Images bằng CLI (cần Internet)\n",
                                        "PIP_INSTALL_OPENIM = True  # True để cho phép pip install openimages CLI\n",
                                        "WORKERS_OVERRIDE = None  # số nguyên để ép số worker, None = tự động\n",
                                        "\n",
                                        "for path in [IMAGE_ROOT / \"val\", IMAGE_ROOT / \"test\", ANN_ROOT, OUTPUT_DIR]:\n",
                                        "    path.mkdir(parents=True, exist_ok=True)\n",
                                        "\n",
                                        "print(f\"VAL_JSON exists: {VAL_JSON.exists()} -> {VAL_JSON}\")\n",
                                        "print(f\"TEST_JSON exists: {TEST_JSON.exists()} -> {TEST_JSON}\")\n",
                                        "print(f\"COCO train exists: {COCO_IMG_TRAIN.exists()} -> {COCO_IMG_TRAIN}\")\n",
                                        "print(f\"COCO val exists: {COCO_IMG_VAL.exists()} -> {COCO_IMG_VAL}\")\n",
                                        "print(f\"OpenImages root: {OPENIM_ROOT if OPENIM_ROOT else 'None'}\")\n",
                                        "print(f\"CLI_SCRIPT (preferred): {CLI_SCRIPT}\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import subprocess\n",
                                        "import sys\n",
                                        "\n",
                                        "try:\n",
                                        "    if not REPO_DIR.exists():\n",
                                        "        subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
                                        "    else:\n",
                                        "        print(f\"Repository already available at {REPO_DIR}\")\n",
                                        "\n",
                                        "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=REPO_DIR).decode().strip()\n",
                                        "    print(\"Repository commit:\", commit)\n",
                                        "    for rel_path in [\"eval_nocaps.py\", \"data/nocaps_dataset.py\", \"configs/nocaps.yaml\"]:\n",
                                        "        path = REPO_DIR / rel_path\n",
                                        "        status = \"OK\" if path.exists() else \"MISSING\"\n",
                                        "        print(f\"{rel_path}: {status}\")\n",
                                        "except Exception as e:\n",
                                        "    print(\"Repo clone/check skipped or failed:\", e)\n",
                                        "finally:\n",
                                        "    # Resolve CLI script path (prefer local tools/ if present)\n",
                                        "    if not PREFER_LOCAL_CLI.exists():\n",
                                        "        CLI_SCRIPT = REPO_DIR / \"tools/run_nocaps_eval.py\"\n",
                                        "    else:\n",
                                        "        CLI_SCRIPT = PREFER_LOCAL_CLI\n",
                                        "    print(\"CLI script resolved to:\", CLI_SCRIPT)\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import subprocess\n",
                                        "import sys\n",
                                        "\n",
                                        "requirements_path = REPO_DIR / \"requirements.txt\"\n",
                                        "if REPO_DIR.exists() and requirements_path.exists():\n",
                                        "    try:\n",
                                        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(requirements_path)], check=True)\n",
                                        "    except Exception as e:\n",
                                        "        print(\"Skipping requirements install (error):\", e)\n",
                                        "else:\n",
                                        "    print(\"Skipping requirements install: REPO_DIR or requirements.txt missing\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "id": "acabfb0d",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import os\n",
                                        "from pathlib import Path\n",
                                        "import torch\n",
                                        "import timm\n",
                                        "\n",
                                        "if REPO_DIR.exists():\n",
                                        "    os.chdir(REPO_DIR)\n",
                                        "    print(\"Working directory:\", Path.cwd())\n",
                                        "else:\n",
                                        "    print(\"REPO_DIR not found (using current working directory):\", Path.cwd())\n",
                                        "print(\"Torch:\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n",
                                        "print(\"Timm:\", timm.__version__)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def summarize_image(entry):\n",
                                        "    keys = [\"file_name\", \"id\", \"domain\", \"coco_url\", \"open_images_id\"]\n",
                                        "    return {k: entry.get(k) for k in keys if k in entry}\n",
                                        "\n",
                                        "with open(VAL_JSON, \"r\") as f:\n",
                                        "    val_raw = json.load(f)\n",
                                        "with open(TEST_JSON, \"r\") as f:\n",
                                        "    test_raw = json.load(f)\n",
                                        "\n",
                                        "val_caps = val_raw.get(\"annotations\", [])\n",
                                        "print(\"Val keys:\", list(val_raw.keys()))\n",
                                        "print(\"Val images:\", len(val_raw[\"images\"]))\n",
                                        "print(\"Val annotations:\", len(val_caps))\n",
                                        "print(\"Val sample image:\", summarize_image(val_raw[\"images\"][0]))\n",
                                        "print(\"Val sample captions:\", [ann[\"caption\"] for ann in val_caps[:3]])\n",
                                        "\n",
                                        "print(\"Test keys:\", list(test_raw.keys()))\n",
                                        "print(\"Test images:\", len(test_raw[\"images\"]))\n",
                                        "print(\"Test has annotations:\", \"annotations\" in test_raw)\n",
                                        "print(\"Test sample image:\", summarize_image(test_raw[\"images\"][0]))"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "id": "b19e4ad2",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import json\n",
                                        "import multiprocessing\n",
                                        "import subprocess\n",
                                        "import sys\n",
                                        "\n",
                                        "workers_detected = multiprocessing.cpu_count() or 1\n",
                                        "workers = WORKERS_OVERRIDE or min(32, max(4, workers_detected))\n",
                                        "print(f\"Detected CPU cores: {workers_detected} -> using {workers} workers\")\n",
                                        "\n",
                                        "cmd = [\n",
                                        "    sys.executable,\n",
                                        "    str(CLI_SCRIPT),\n",
                                        "    \"--dataset-root\", str(DATASET_ROOT),\n",
                                        "    \"--image-root\", str(IMAGE_ROOT),\n",
                                        "    \"--ann-root\", str(ANN_ROOT),\n",
                                        "    \"--output-dir\", str(OUTPUT_DIR),\n",
                                        "    \"--batch-size\", \"4\",\n",
                                        "    \"--workers\", str(workers),\n",
                                        "]\n",
                                        "# Detect supported flags by scanning the script text\n",
                                        "try:\n",
                                        "    script_text = open(CLI_SCRIPT, 'r', encoding='utf-8', errors='ignore').read()\n",
                                        "except Exception:\n",
                                        "    script_text = ''\n",
                                        "from pathlib import Path\n",
                                        "if not Path(CLI_SCRIPT).exists():\n",
                                        "    raise FileNotFoundError(f\"Missing CLI script {CLI_SCRIPT}. Clone the repo or attach it as a Kaggle dataset.\")\n",
                                        "\n",
                                        "def supports(flag: str) -> bool:\n",
                                        "    return (flag in script_text)\n",
                                        "\n",
                                        "if supports('coco-train-root'):\n",
                                        "    cmd += [\"--coco-train-root\", str(COCO_IMG_TRAIN)]\n",
                                        "if supports('coco-val-root'):\n",
                                        "    cmd += [\"--coco-val-root\", str(COCO_IMG_VAL)]\n",
                                        "if OPENIM_ROOT and supports('openimages-root'):\n",
                                        "    cmd += [\"--openimages-root\", str(OPENIM_ROOT)]\n",
                                        "if SKIP_DOWNLOAD:\n",
                                        "    cmd.append(\"--no-download\")\n",
                                        "else:\n",
                                        "    if USE_OPENIM_CLI and supports('use-openimages-cli'):\n",
                                        "        cmd.append(\"--use-openimages-cli\")\n",
                                        "        if PIP_INSTALL_OPENIM and supports('pip-install-openimages'):\n",
                                        "            cmd.append(\"--pip-install-openimages\")\n",
                                        "\n",
                                        "print(\"Running:\", \" \".join(cmd))\n",
                                        "subprocess.run(cmd, check=True)\n",
                                        "\n",
                                        "failures_log = OUTPUT_DIR / \"download_failures.json\"\n",
                                        "if failures_log.exists():\n",
                                        "    failures = json.loads(failures_log.read_text())\n",
                                        "    print(\"Download failures - val:\", len(failures.get(\"val\", [])), \"| test:\", len(failures.get(\"test\", [])))\n",
                                        "else:\n",
                                        "    print(\"No download_failures.json found yet.\")\n",
                                        "if not EVAL_WITH_SCRIPT:\n",
                                        "    cmd.append(\"--skip-eval\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "id": "af75951a",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import json\n",
                                        "\n",
                                        "val_out = ANN_ROOT / \"nocaps_val.json\"\n",
                                        "test_out = ANN_ROOT / \"nocaps_test.json\"\n",
                                        "failures_log = OUTPUT_DIR / \"download_failures.json\"\n",
                                        "\n",
                                        "if val_out.exists():\n",
                                        "    val_entries = json.loads(val_out.read_text())\n",
                                        "    print(\"Val entries:\", len(val_entries), \"->\", val_out)\n",
                                        "    if val_entries:\n",
                                        "        print(\"Sample val entry:\", val_entries[0])\n",
                                        "else:\n",
                                        "    print(\"Val annotations not ready yet (rerun the data download cell).\")\n",
                                        "\n",
                                        "if test_out.exists():\n",
                                        "    test_entries = json.loads(test_out.read_text())\n",
                                        "    print(\"Test entries:\", len(test_entries), \"->\", test_out)\n",
                                        "    if test_entries:\n",
                                        "        print(\"Sample test entry:\", test_entries[0])\n",
                                        "else:\n",
                                        "    print(\"Test annotations not ready yet (rerun the data download cell).\")\n",
                                        "\n",
                                        "if failures_log.exists():\n",
                                        "    failures = json.loads(failures_log.read_text())\n",
                                        "    print(\"Download failure samples (val):\", failures.get(\"val\", [])[:3])\n",
                                        "    print(\"Download failure samples (test):\", failures.get(\"test\", [])[:3])\n",
                                        "else:\n",
                                        "    print(\"No download_failures.json found (no errors or download not finished yet).\")"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "id": "63171df0",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import json\n",
                                        "from pathlib import Path\n",
                                        "\n",
                                        "try:\n",
                                        "    import ruamel_yaml as yaml  # type: ignore[import]\n",
                                        "except ModuleNotFoundError:\n",
                                        "    try:\n",
                                        "        from ruamel import yaml  # type: ignore\n",
                                        "    except ModuleNotFoundError:\n",
                                        "        import yaml  # type: ignore\n",
                                        "\n",
                                        "expected_config = OUTPUT_DIR / \"nocaps_eval.yaml\"\n",
                                        "if expected_config.exists():\n",
                                        "    config_path = expected_config\n",
                                        "    config = yaml.load(expected_config.read_text(), Loader=yaml.Loader)\n",
                                        "else:\n",
                                        "    print(\"WARNING: not found\", expected_config, \"-> falling back to template.\")\n",
                                        "    config_path = Path(\"configs/nocaps.yaml\")\n",
                                        "    config = yaml.load(config_path.read_text(), Loader=yaml.Loader)\n",
                                        "    config[\"image_root\"] = str(IMAGE_ROOT).replace(\"\\\\\", \"/\")\n",
                                        "    config[\"ann_root\"] = str(ANN_ROOT).replace(\"\\\\\", \"/\")\n",
                                        "    config[\"batch_size\"] = min(4, config.get(\"batch_size\", 32))\n",
                                        "    expected_config = OUTPUT_DIR / \"nocaps_eval.yaml\"\n",
                                        "    expected_config.write_text(yaml.dump(config))\n",
                                        "    print(\"Wrote new config to:\", expected_config)\n",
                                        "\n",
                                        "print(\"Config path:\", expected_config)\n",
                                        "print(json.dumps(config, indent=2))"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "id": "4f26698c",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import subprocess, sys\n",
                                        "from pathlib import Path\n",
                                        "\n",
                                        "if EVAL_WITH_SCRIPT:\n",
                                        "    print(\"Skipping separate eval; already done inside CLI script.\")\n",
                                        "else:\n",
                                        "    subprocess.run([sys.executable, \"eval_nocaps.py\", \"--config\", \"/kaggle/working/nocaps_eval.yaml\", \"--output_dir\", \"/kaggle/working/NoCaps\", \"--device\", \"cuda\", \"--distributed\", \"False\"], check=True)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "result_dir = OUTPUT_DIR / \"result\"\n",
                                        "val_result_path = result_dir / \"val.json\"\n",
                                        "test_result_path = result_dir / \"test.json\"\n",
                                        "\n",
                                        "with open(val_result_path, \"r\") as f:\n",
                                        "    val_result = json.load(f)\n",
                                        "with open(test_result_path, \"r\") as f:\n",
                                        "    test_result = json.load(f)\n",
                                        "\n",
                                        "print(\"Val captions:\", len(val_result))\n",
                                        "print(\"Test captions:\", len(test_result))\n",
                                        "print(\"Sample val captions:\")\n",
                                        "for sample in val_result[:5]:\n",
                                        "    print(sample)\n",
                                        "\n",
                                        "print(\"Artifacts saved under:\", OUTPUT_DIR)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Next steps\n",
                                        "- If `download_failures.json` is not empty, consider manually downloading those images and rerunning the conversion cell.\n",
                                        "- Compress `nocaps_images`, `nocaps_annotations`, and `NoCaps/result/test.json` into a separate Kaggle dataset so future notebook runs are faster.\n",
                                        "- Upload `NoCaps/result/test.json` to the NoCaps server to receive the official score."
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "Python 3",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.10"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 5
}
